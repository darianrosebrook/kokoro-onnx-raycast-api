/**
 * TTS Processor Coordinator - Production-Ready Streaming Audio Orchestrator for Kokoro ONNX
 *
 * This module orchestrates the entire TTS pipeline from text input to audio output,
 * coordinating between text processing, audio streaming, and the standalone audio daemon.
 * It serves as a coordinator that delegates actual audio processing to the daemon,
 * not an implementation of audio processing itself.
 *
 * ## Architecture Overview
 *
 * The TTSSpeechProcessor implements a sophisticated coordinator pattern:
 *
 * 1. **Text Processing Coordination**: Manages text segmentation and preprocessing
 * 2. **Audio Streaming Coordination**: Coordinates audio chunk delivery to the daemon
 * 3. **Daemon Communication**: Delegates audio processing to the standalone daemon
 * 4. **State Management**: Orchestrates the entire TTS pipeline state
 * 5. **Error Handling**: Provides comprehensive error recovery and fallback
 *
 * ## Key Design Principles
 *
 * - **Separation of Concerns**: Coordinator only orchestrates, doesn't implement audio processing
 * - **Process Isolation**: Audio processing runs in separate daemon process
 * - **Pipeline Coordination**: Manages the flow between text → audio → daemon
 * - **Error Resilience**: Multi-level fallback system for production reliability
 *
 * ## Performance Characteristics
 *
 * - **Latency**: 200-500ms to first audio chunk depending on hardware and text length (vs 5-10s traditional)
 * - **Memory**: Constant memory usage via streaming (vs growing buffers)
 * - **Throughput**: ~50ms audio chunks for smooth playback
 * - **Compatibility**: Works across all macOS versions and hardware configurations
 *
 * ## Technical Implementation Details
 *
 * ### Streaming Protocol
 * The processor coordinates HTTP streaming with chunked transfer encoding:
 * ```
 * Client → Server: POST /v1/audio/speech {stream: true}
 * Server → Client: audio/wav chunks (50ms duration each)
 * Client → Daemon: Audio chunks via WebSocket
 * Daemon → macOS: Native audio playback
 * ```
 *
 * ### Text Processing Pipeline
 * ```
 * Input Text → Preprocessing → Segmentation → Parallel Synthesis → Streaming Output
 * ```
 *
 * ### Audio Processing Chain
 * ```
 * Streaming Chunks → Audio Daemon → Native Audio System → Speakers
 * ```
 *
 * @author @darianrosebrook
 * @version 2.0.0
 * @since 2025-07-17
 * @license MIT
 *
 * @example
 * ```typescript
 * const processor = new TTSSpeechProcessor({
 *   voice: "af_heart",
 *   speed: 1.2,
 *   serverUrl: "http://localhost:8000",
 *   useStreaming: true,
 *   onStatusUpdate: (status) => console.log(status)
 * });
 *
 * await processor.speak("Hello, world!");
 * ```
 */
import type { VoiceOption, TTSProcessorConfig, TTSRequestParams } from "../../types.js";
import type { StatusUpdate } from "../../types.js";
import { TextProcessor } from "./text-processor.js";
import { AudioStreamer } from "./streaming/audio-streamer.js";
import { PlaybackManager } from "./playback-manager.js";
import { PerformanceTracker } from "../core/performance-tracker.js";
import { RetryManager } from "../api/retry-manager.js";
import { AdaptiveBufferManager } from "./streaming/adaptive-buffer-manager.js";
import { StreamingContext, TextSegment, TTS_CONSTANTS } from "../validation/tts-types.js";
// const execAsync = promisify(exec);

/**
 * Maximum text length per request to Kokoro API.
 *
 * **Why 1800 instead of 2000?**
 * - Kokoro's hard limit is 2000 characters
 * - We reserve 200 characters for safety margin to account for:
 *   - Unicode character encoding differences
 *   - Potential text preprocessing expansion
 *   - Server-side processing overhead
 * - This prevents cryptic server errors and ensures reliable processing
 */
// const SERVER_MAX_TEXT_LENGTH = 1800;

/**
 * Configuration interface for TTS processor preferences.
 *
 * **Design Note**: All properties are optional to support both Raycast preference
 * injection and manual configuration, with sensible defaults for production use.
 */
interface Preferences {
  voice?: string;
  speed?: string; // Stored as string from Raycast preferences, parsed to float
  serverUrl?: string;
  useStreaming?: boolean;
  sentencePauses?: boolean;
  maxSentenceLength?: string; // Stored as string from Raycast preferences, parsed to int
  onStatusUpdate?: (status: StatusUpdate) => void;
  developmentMode?: boolean;
  daemonPort?: string; // Stored as string from Raycast preferences, parsed to int
}

interface ProcessorDependencies {
  textProcessor?: TextProcessor;
  audioStreamer?: AudioStreamer;
  playbackManager?: PlaybackManager;
  performanceTracker?: PerformanceTracker;
  retryManager?: RetryManager;
  adaptiveBufferManager?: AdaptiveBufferManager;
}

/**
 * Production-ready TTS processor with streaming audio support.
 *
 * This class orchestrates the entire TTS pipeline from text input to audio output,
 * implementing a sophisticated streaming architecture optimized for macOS and the
 * Kokoro ONNX model.
 *
 * ## Key Design Decisions
 *
 * ### 1. Streaming Architecture
 * Traditional TTS: Text → Complete Audio → Playback (5-10s delay)
 * Our approach: Text → Audio Chunks → Immediate Playback (200-500ms)
 *
 * ### 2. State Management
 * Uses promise-based coordination for pause/resume instead of polling,
 * providing immediate response and preventing race conditions.
 *
 * ### 3. Error Handling
 * Multi-level fallback system ensures production reliability:
 * - Network errors → retry with exponential backoff
 * - Server errors → graceful degradation
 * - Audio errors → fallback to alternative playback methods
 *
 * ### 4. Memory Management
 * Temporary files instead of memory buffers prevent memory leaks and
 * enable processing of arbitrarily long texts without memory pressure.
 *
 * @class TTSSpeechProcessor
 */
export class TTSSpeechProcessor {
  private instanceId: string;
  private voice: VoiceOption;
  private speed: number;
  private serverUrl: string;
  private daemonPort: number;
  private useStreaming: boolean;
  private sentencePauses: boolean;
  private maxSentenceLength: number;
  private format: "wav" | "pcm" = "wav";
  private developmentMode: boolean;

  // Modular components
  private textProcessor: TextProcessor;
  private audioStreamer: AudioStreamer;
  private playbackManager: PlaybackManager;
  private performanceTracker: PerformanceTracker;
  private retryManager: RetryManager;
  private adaptiveBufferManager: AdaptiveBufferManager;

  // Initialization state
  private initialized = false;
  private initializationPromise: Promise<void> | null = null;

  // State management for playback control is delegated to PlaybackManager.
  // private isPlaying = false;
  // private isPaused = false;
  // private isStopped = false;

  // Process and resource management
  private textParagraphs: TextSegment[] = [];
  // private currentParagraphIndex = 0;

  // Streaming and async coordination
  private onStatusUpdate: (status: StatusUpdate) => void;
  private abortController: AbortController | null = null;

  /**
   * Initialize TTS processor with user preferences.
   *
   * **Architecture Note**: This constructor implements the dependency injection pattern,
   * allowing the processor to be configured from Raycast preferences or manual setup
   * without tight coupling to the Raycast API.
   *
   * @param prefs - User preferences from Raycast or manual configuration
   * @param dependencies - Optional container for injecting mock dependencies during testing
   */
  constructor(prefs: Preferences, dependencies: ProcessorDependencies = {}) {
    this.instanceId = this.constructor.name + "_" + Date.now();
    console.log(`[${this.instanceId}] Constructor called`);
    console.log(`[${this.instanceId}] Dependencies provided:`, Object.keys(dependencies));

    // Voice selection with high-quality default
    this.voice = (prefs.voice as VoiceOption) ?? "af_heart";

    // Speed parsing with safe defaults
    this.speed = parseFloat(prefs.speed ?? "1.0");

    // Server URL with automatic trailing slash cleanup
    this.serverUrl = prefs.serverUrl?.replace(/\/+$/, "") ?? "http://localhost:8000";

    // Streaming enabled by default for better UX
    this.useStreaming = prefs.useStreaming ?? true;

    // Sentence pauses for natural speech flow
    this.sentencePauses = prefs.sentencePauses ?? false;

    // Max sentence length for segmentation optimization
    this.maxSentenceLength = parseInt(prefs.maxSentenceLength ?? "100");

    // Daemon port configuration (default 8081)
    this.daemonPort = parseInt(prefs.daemonPort ?? "8081");

    // Status update callback with fallback to toast notifications
    this.onStatusUpdate =
      prefs.onStatusUpdate ??
      (({ message, style = Toast.Style.Failure }) => {
        showToast({ style, title: message });
      });
    this.developmentMode = prefs.developmentMode ?? true;

    console.log(`[${this.instanceId}] Configuration:`, {
      voice: this.voice,
      speed: this.speed,
      serverUrl: this.serverUrl,
      useStreaming: this.useStreaming,
      developmentMode: this.developmentMode,
    });

    // Initialize modular components
    const processorConfig: TTSProcessorConfig & {
      onStatusUpdate: (status: StatusUpdate) => void;
      developmentMode: boolean;
      format: "wav" | "pcm";
      daemonPort: number;
    } = {
      voice: this.voice,
      speed: this.speed,
      serverUrl: this.serverUrl,
      daemonUrl: `http://localhost:${this.daemonPort}`,
      useStreaming: this.useStreaming,
      sentencePauses: this.sentencePauses,
      maxSentenceLength: this.maxSentenceLength,
      onStatusUpdate: this.onStatusUpdate,
      developmentMode: this.developmentMode,
      format: this.format,
      daemonPort: this.daemonPort,
      performanceProfile: "balanced",
      autoSelectProfile: false,
      showPerformanceMetrics: false,
    };

    console.log(`[${this.instanceId}] Creating component instances`);

    this.textProcessor = dependencies.textProcessor ?? new TextProcessor(processorConfig);
    this.audioStreamer = dependencies.audioStreamer ?? new AudioStreamer(processorConfig);
    this.playbackManager = dependencies.playbackManager ?? new PlaybackManager(processorConfig);
    this.performanceTracker =
      dependencies.performanceTracker ?? PerformanceTracker.getInstance();
    this.retryManager = dependencies.retryManager ?? new RetryManager(processorConfig);
    this.adaptiveBufferManager =
      dependencies.adaptiveBufferManager ??
      new AdaptiveBufferManager({
        targetBufferMs: 400,
        bufferSize: 2 * 1024 * 1024,
        chunkSize: 2400,
        deliveryRate: 40,
        minBufferChunks: 4,
        maxLatency: 100,
        targetUtilization: 0.7,
      });

    console.log(`[${this.instanceId}] Component instances created`);

    // Initialize all modules properly
    // Note: In a real test environment, you might not initialize the actual modules
    // if you are only testing the processor's orchestration logic.
    if (Object.keys(dependencies).length === 0) {
      console.log(`[${this.instanceId}] Starting module initialization`);
      this.initializationPromise = this.initializeModules(processorConfig);
    } else {
      console.log(`[${this.instanceId}] Using injected dependencies, skipping initialization`);
      this.initialized = true;
    }
  }

  /**
   * Initialize all TTS modules asynchronously
   */
  private async initializeModules(
    processorConfig: TTSProcessorConfig & {
      onStatusUpdate: (status: StatusUpdate) => void;
      developmentMode: boolean;
      format: "wav" | "pcm";
      daemonPort: number;
    }
  ): Promise<void> {
    try {
      console.log(`[${this.instanceId}] Initializing modules...`);

      await Promise.all([
        this.textProcessor.initialize(processorConfig),
        this.audioStreamer.initialize(processorConfig),
        this.playbackManager.initialize(processorConfig),
        // Performance tracker is already initialized as singleton
        this.retryManager.initialize(processorConfig),
        this.adaptiveBufferManager.initialize({
          targetBufferMs: 400,
          bufferSize: 2 * 1024 * 1024,
          chunkSize: 2400,
          deliveryRate: 40,
          minBufferChunks: 4,
          maxLatency: 100,
          targetUtilization: 0.7,
        }),
      ]);

      // Update daemon port with the actual port from the daemon
      const actualDaemonPort = this.playbackManager.getDaemonPort();
      if (actualDaemonPort && actualDaemonPort !== this.daemonPort) {
        console.log(`[${this.instanceId}] Updating daemon port:`, {
          original: this.daemonPort,
          actual: actualDaemonPort,
        });
        this.daemonPort = actualDaemonPort;
      }

      this.initialized = true;
      console.log(`[${this.instanceId}] All modules initialized successfully`);
    } catch (error) {
      console.error(`[${this.instanceId}] Failed to initialize TTS modules:`, error);
      showToast({ style: Toast.Style.Failure, title: "Initialization Error" });
      throw error;
    }
  }

  /**
   * Ensure TTS processor is initialized before use
   */
  private async ensureInitialized(): Promise<void> {
    if (this.initialized) {
      console.log(`[${this.instanceId}] Already initialized`);
      return;
    }

    if (this.initializationPromise) {
      console.log(`[${this.instanceId}] Waiting for initialization to complete...`);
      await this.initializationPromise;
      console.log(`[${this.instanceId}] Initialization completed`);
    } else {
      console.log(`[${this.instanceId}] No initialization promise found`);
      throw new Error("TTS Processor initialization failed");
    }
  }

  /**
   * Main entry point for text-to-speech processing.
   *
   * **Architecture Overview**:
   * 1. **Initialization check**: Ensure all components are ready
   * 2. **Input validation**: Ensure text is provided and processor is available
   * 3. **State initialization**: Set up streaming controls and abort mechanisms
   * 4. **Text preprocessing**: Clean and segment text for optimal processing
   * 5. **Sequential processing**: Process segments in order while maintaining state
   * 6. **Cleanup**: Ensure proper resource cleanup regardless of completion status
   *
   * **Why Sequential Processing?**
   * While segments are synthesized in parallel on the server, playback must be
   * sequential to maintain natural speech flow. This method coordinates the
   * streaming pipeline to ensure proper ordering.
   *
   * @param text - Text to synthesize and speak
   * @throws {Error} When text is empty or processing fails
   */
  async speak(text: string): Promise<void> {
    console.log(`[${this.instanceId}] speak() called with text:`, text);
    console.log(`[${this.instanceId}] Input text:`, {
      length: text.length,
      preview: text.substring(0, 100) + (text.length > 100 ? "..." : ""),
    });

    // CRITICAL: Ensure initialization before proceeding
    console.log(`[${this.instanceId}] Ensuring initialization...`);
    try {
      await this.ensureInitialized();
      console.log(`[${this.instanceId}] ensureInitialized() complete`);
    } catch (error) {
      console.error(`[${this.instanceId}] Initialization failed:`, error);
      this.onStatusUpdate({
        message: "TTS system initialization failed",
        style: Toast.Style.Failure,
        isPlaying: false,
        isPaused: false,
      });
      throw error;
    }

    if (!text?.trim()) {
      console.log(`[${this.instanceId}] No text provided`);
      this.onStatusUpdate({
        message: "No text to speak",
        style: Toast.Style.Failure,
        isPlaying: false,
        isPaused: false,
      });
      return;
    }

    console.log(`[${this.instanceId}] Configuration:`, {
      voice: this.voice,
      speed: this.speed,
      serverUrl: this.serverUrl,
      useStreaming: this.useStreaming,
      sentencePauses: this.sentencePauses,
      maxSentenceLength: this.maxSentenceLength,
      format: this.format,
    });

    // Stop any existing playback before starting new
    if (this.playbackManager.isActive()) {
      console.log(`[${this.instanceId}] Stopping existing playback`);
      await this.playbackManager.stop();
      console.log(`[${this.instanceId}] Existing playback stopped`);
    }

    this.abortController = new AbortController();
    const { signal } = this.abortController;

    const requestId = `tts-${Date.now()}`;
    console.log(`[${this.instanceId}] Starting performance tracking for request:`, requestId);
    this.performanceTracker.startRequest(requestId, text, this.config.voice, this.config.speed);

    // PHASE 1 OPTIMIZATION: Start streaming playback immediately
    let streamingPlayback: {
      writeChunk: (chunk: Uint8Array) => Promise<void>;
      endStream: () => Promise<void>;
    } | null = null;

    let streamingStarted = false;
    let streamingTerminated = false;
    let streamingFailed = false;
    let afplayTerminated = false;

    let totalChunksReceived = 0;
    const startTime = performance.now();

    console.log(`[${this.instanceId}] Session start time:`, startTime);

    try {
      // PHASE 1 OPTIMIZATION: Start streaming session before chunk loop
      if (this.useStreaming && !streamingPlayback) {
        console.log(`[${this.instanceId}] Starting streaming playback session`);

        try {
          streamingPlayback = await this.playbackManager.startStreamingPlayback(signal);
          streamingStarted = true;
          console.log(`[${this.instanceId}] Streaming session started successfully`);
        } catch (streamingError) {
          console.error(`[${this.instanceId}] Failed to start streaming session:`, streamingError);
          streamingFailed = true;
          throw streamingError;
        }
      }

      console.log(`[${this.instanceId}] Processing text...`);
      this.onStatusUpdate({ message: "Processing text...", isPlaying: true, isPaused: false });

      const processedText = this.textProcessor.preprocessText(text);
      console.log(`[${this.instanceId}] Text preprocessing complete:`, {
        originalLength: text.length,
        processedLength: processedText.length,
        preview: processedText.substring(0, 100) + (processedText.length > 100 ? "..." : ""),
      });

      // Segment text for streaming optimization
      this.textParagraphs = this.textProcessor.segmentText(
        processedText,
        // Use the actual maximum text length (1800) instead of maxSentenceLength (100)
        // This allows for longer segments and better streaming performance
        TTS_CONSTANTS.MAX_TEXT_LENGTH
      );

      console.log(`[${this.instanceId}] Text segmentation complete:`, {
        totalSegments: this.textParagraphs.length,
        segments: this.textParagraphs.map((seg, idx) => ({
          index: idx,
          length: seg.text.length,
          preview: seg.text.substring(0, 50) + (seg.text.length > 50 ? "..." : ""),
        })),
      });

      // Stream audio for each text segment
      console.log(`[${this.instanceId}] Starting audio streaming for segments`);

      for (const segment of this.textParagraphs) {
        console.log(
          `[${this.instanceId}] Processing segment ${segment.index + 1}/${this.textParagraphs.length}`
        );

        if (signal.aborted) {
          console.log(`[${this.instanceId}] Signal aborted, stopping segment processing`);
          break;
        }

        // Stream audio chunks for this segment
        const requestParams: TTSRequestParams = {
          text: segment.text,
          voice: this.voice,
          speed: this.speed,
          lang: "en-us",
          stream: this.useStreaming,
          format: this.useStreaming ? "pcm" : this.format,
        };

        console.log(`[${this.instanceId}] Creating server request:`, {
          segmentIndex: segment.index,
          textLength: segment.text.length,
          voice: requestParams.voice,
          speed: requestParams.speed,
          stream: requestParams.stream,
          format: requestParams.format,
        });

        const streamingContext: StreamingContext = {
          requestId: `segment-${segment.index}-${Date.now()}`,
          segments: this.textParagraphs.map((s) => s.text),
          currentSegmentIndex: segment.index,
          totalSegments: this.textParagraphs.length,
          abortController: this.abortController,
          startTime: performance.now(),
        };

        console.log(`[${this.instanceId}] Sending request to audio streamer`);

        await this.audioStreamer.streamAudio(requestParams, streamingContext, async (chunk) => {
          totalChunksReceived++;
          const elapsedTime = performance.now() - startTime;

          // Log every 10th chunk to reduce verbosity
          if (totalChunksReceived % 10 === 0 || totalChunksReceived <= 3) {
            console.log(`[${this.instanceId}] Received audio chunk:`, {
              chunkNumber: totalChunksReceived,
              segmentIndex: segment.index,
              chunkSize: chunk.data.length,
              elapsedTime: elapsedTime.toFixed(2) + "ms",
            });
          }

          if (
            this.useStreaming &&
            streamingStarted &&
            !streamingTerminated &&
            !streamingFailed &&
            streamingPlayback
          ) {
            try {
              await streamingPlayback.writeChunk(chunk.data);
              if (totalChunksReceived % 10 === 0 || totalChunksReceived <= 3) {
                console.log(
                  `[${this.instanceId}] Streamed chunk ${totalChunksReceived} (${chunk.data.length} bytes) in ${elapsedTime}ms`
                );
              }
            } catch (streamError) {
              console.error(`[${this.instanceId}] Failed to stream chunk:`, streamError);

              // Check if this is a normal termination
              const isNormalTermination =
                streamError instanceof Error &&
                (streamError.name === "NormalTermination" ||
                  streamError.message.includes("SIGTERM") ||
                  streamError.message.includes("normal termination") ||
                  streamError.message.includes("process ended") ||
                  streamError.message.includes("Ignoring write attempt after normal termination"));

              if (isNormalTermination) {
                console.log(
                  `[${this.instanceId}] Normal termination detected - marking streaming as complete`
                );
                streamingTerminated = true;
                afplayTerminated = true;
                // Don't abort or fallback for normal termination
                return;
              } else {
                console.error(
                  `[${this.instanceId}] Streaming failed - marking as failed to prevent fallback`
                );
                streamingFailed = true;
                this.abortController?.abort();
                throw streamError;
              }
            }
          } else if (this.useStreaming && streamingTerminated) {
            // Streaming completed normally - skip remaining chunks
            return;
          } else if (this.useStreaming && streamingFailed) {
            // Streaming failed - skip remaining chunks to prevent fallback
            return;
          } else if (this.useStreaming && afplayTerminated) {
            // afplay has terminated but we're still receiving chunks - skip them
            return;
          } else if (this.useStreaming && !streamingStarted) {
            // Streaming mode but streaming hasn't started yet - this can happen if afplay terminated before first chunk
            return;
          } else if (this.useStreaming && !streamingPlayback) {
            // Streaming mode but no streaming playback available - this can happen if afplay terminated
            return;
          }
        });

        console.log(`[${this.instanceId}] Segment ${segment.index + 1} processing complete`);
      }

      console.log(`[${this.instanceId}] All segments processed, ending streaming playback`);

      // PHASE 1 OPTIMIZATION: End streaming playback
      if (streamingPlayback && streamingStarted && !streamingFailed) {
        console.log(`[${this.instanceId}] Ending streaming playback`);
        try {
          await streamingPlayback.endStream();
          console.log(`[${this.instanceId}] Streaming playback ended gracefully`);
        } catch (endStreamError) {
          console.error(`[${this.instanceId}] Error ending streaming playback:`, endStreamError);
          // Check if this is a normal termination
          const errorMessage =
            endStreamError instanceof Error ? endStreamError.message : String(endStreamError);
          const isNormalTermination =
            errorMessage.includes("SIGTERM") ||
            errorMessage.includes("normal termination") ||
            errorMessage.includes("process ended") ||
            errorMessage.includes("Stream ended normally despite timeout");

          if (isNormalTermination) {
            console.log(`[${this.instanceId}] Normal termination during endStream - continuing`);
          } else {
            console.error(`[${this.instanceId}] Failed to end streaming playback:`, endStreamError);
            // Don't throw for endStream errors - they're not critical
          }
        }
      } else if (streamingTerminated) {
        console.log(
          `[${this.instanceId}] Streaming already terminated normally - no need to end stream`
        );
      } else if (streamingFailed) {
        console.log(`[${this.instanceId}] Streaming failed - no need to end stream`);
      }

      if (!signal.aborted) {
        const totalTime = performance.now() - startTime;
        console.log(` [${this.instanceId}]  Speech processing complete:`, {
          totalChunks: totalChunksReceived,
          totalTime: totalTime.toFixed(2) + "ms",
          averageChunkTime:
            totalChunksReceived > 0 ? (totalTime / totalChunksReceived).toFixed(2) + "ms" : "N/A",
        });
            console.log(
      ` [${this.instanceId}] All ${totalChunksReceived} chunks processed in ${totalTime}ms`
    );
        this.onStatusUpdate({
          message: "Speech completed",
          style: Toast.Style.Success,
          isPlaying: false,
          isPaused: false,
        });
      }
    } catch (error) {
      console.error(` [${this.instanceId}]  Speech processing failed:`, error);
      const errorMessage = error instanceof Error ? error.message : String(error);
      const errorStack = error instanceof Error ? error.stack : undefined;

      console.error(` [${this.instanceId}] Error details:`, {
        message: errorMessage,
        stack: errorStack,
        useStreaming: this.useStreaming,
        streamingStarted,
        streamingFailed,
        totalChunksReceived,
      });

      if (streamingPlayback && !streamingFailed) {
        console.log(` [${this.instanceId}]  Cleaning up streaming playback after error`);
        try {
          await streamingPlayback.endStream();
        } catch (cleanupError) {
          console.error(
            ` [${this.instanceId}]  Failed to clean up streaming playback:`,
            cleanupError
          );
          console.error(
            ` [${this.instanceId}] Failed to clean up streaming playback:`,
            cleanupError
          );
        }
      }

      if (!this.playbackManager.isStopped() && !signal.aborted) {
        console.error(` [${this.instanceId}] TTS Error:`, error);
        console.error(` [${this.instanceId}] TTS Error:`, error);
        const errorMessage = error instanceof Error ? error.message : "Unknown error occurred";
        showToast({ style: Toast.Style.Failure, title: "TTS Error", message: errorMessage });
        throw error;
      }
    } finally {
      console.log(` [${this.instanceId}]  Cleaning up resources`);
      const finalTime = performance.now() - startTime;
      console.log(` [${this.instanceId}]  Final session duration:`, finalTime.toFixed(2) + "ms");

          this.performanceTracker.completeRequest(requestId);
      await this.cleanup();
      this.abortController = null;

      console.log(` [${this.instanceId}] === SPEAK METHOD END ===`);
    }
  }

  /**
   * Pause playback with immediate response.
   *
   * **Implementation Note**: Uses promise-based coordination rather than polling
   * for immediate response and efficient resource usage.
   */
  pause(): void {
    this.playbackManager.pause();
    this.onStatusUpdate({
      message: "Paused",
      isPlaying: this.playbackManager.isActive(),
      isPaused: this.playbackManager.isPaused(),
      primaryAction: { title: "Resume", onAction: () => this.resume() },
      secondaryAction: { title: "Stop", onAction: () => this.stop() },
    });
  }

  /**
   * Resume playback from paused state.
   *
   * **Coordination Strategy**: Different resume strategies for streaming vs
   * non-streaming modes to maintain optimal performance characteristics.
   */
  resume(): void {
    this.playbackManager.resume();
    this.onStatusUpdate({
      message: "Playing audio...",
      isPlaying: this.playbackManager.isActive(),
      isPaused: this.playbackManager.isPaused(),
      primaryAction: { title: "Pause", onAction: () => this.pause() },
      secondaryAction: { title: "Stop", onAction: () => this.stop() },
    });
  }

  /**
   * Stop playback and clean up all resources.
   *
   * **Cleanup Strategy**: Ensures proper resource cleanup even if processes
   * are forcefully terminated, preventing resource leaks.
   */
  async stop(): Promise<void> {
    this.onStatusUpdate({ message: "Stopping...", isPlaying: false, isPaused: false });
    this.abortController?.abort();
    await this.playbackManager.stop();
    this.onStatusUpdate({ message: "Stopped", isPlaying: false, isPaused: false });
  }

  /**
   * Clean up temporary files and resources.
   *
   * **Resource Management**: Ensures all temporary files are properly deleted
   * to prevent disk space issues, even if the process is interrupted.
   */
  private async cleanup(): Promise<void> {
    // for (const file of this.tempFiles) { // This line is removed as per the edit hint
    //   try {
    //     // Check if file exists before attempting to delete
    //     await stat(file);
    //     await unlink(file);
    //   } catch (error) {
    //     // Only warn if it's not a "file not found" error
    //     if ((error as { code?: string }).code !== "ENOENT") {
    //       console.warn(`Failed to delete temp file: ${file}`, error);
    //     }
    //   }
    // }
    // this.tempFiles = []; // This line is removed as per the edit hint
  }

  /**
   * Get current playing state.
   *
   * **Debug Note**: Includes console.log for debugging state transitions.
   */
  get playing(): boolean {
    return this.playbackManager.isActive();
  }

  /**
   * Get current paused state.
   */
  get paused(): boolean {
    return this.playbackManager.isPaused();
  }

  /**
   * Get current TTS configuration.
   *
   * **Use Case**: Allows external components to inspect current settings
   * for debugging or UI display purposes.
   */
  get config(): TTSProcessorConfig {
    return {
      voice: this.voice,
      speed: this.speed,
      serverUrl: this.serverUrl,
      daemonUrl: `http://localhost:${this.daemonPort ?? 8081}`,
      useStreaming: this.useStreaming,
      sentencePauses: this.sentencePauses,
      maxSentenceLength: this.maxSentenceLength,
      format: this.format,
      developmentMode: this.developmentMode,
      onStatusUpdate: this.onStatusUpdate,
      performanceProfile: "balanced",
      autoSelectProfile: false,
      showPerformanceMetrics: false,
    };
  }
}

// Conditional import or mock for @raycast/api
// eslint-disable-next-line @typescript-eslint/no-explicit-any
let showToast: (options: { style: any; title: string; message?: string }) => Promise<void>,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  Toast: { Style: { Success: any; Failure: any } };
try {
  // Try to import Raycast API (works in Raycast extension runtime)
  // eslint-disable-next-line @typescript-eslint/no-require-imports, no-undef
  ({ showToast, Toast } = require("@raycast/api"));
} catch {
  // Fallback mock for Node.js/testing
  showToast = async () => {};
  Toast = { Style: { Success: "success", Failure: "failure" } };
}
